{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_Named_Entity_Recognition_using_BiLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMaGFNcfgGn2yLdVjtmVVAO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImJongHwan/practice-ml-nlp/blob/main/12_tagging_task/5_Named_Entity_Recognition_using_BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BiLSTM을 이용한 개체명 인식(Named Entity Recognition, NER)\n",
        "\n",
        "https://wikidocs.net/147219"
      ],
      "metadata": {
        "id": "7BQ05wAAhfs3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 개체명 인식 데이터에 대한 이해와 전처리"
      ],
      "metadata": {
        "id": "wO2qzuSEhivh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_hb69PX4gjH1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/12.%20RNN%20Sequence%20Labeling/dataset/ner_dataset.csv\", filename=\"ner_dataset.csv\")\n",
        "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\")"
      ],
      "metadata": {
        "id": "YPv7-BNWhlCj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SAV7MEC_h283",
        "outputId": "e37bcd73-08c4-444c-fc62-5bc8fdb8eb85"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5fea8fd4-7618-40f2-aa49-80c4214e1780\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fea8fd4-7618-40f2-aa49-80c4214e1780')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5fea8fd4-7618-40f2-aa49-80c4214e1780 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5fea8fd4-7618-40f2-aa49-80c4214e1780');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1          NaN             of   IN   O\n",
              "2          NaN  demonstrators  NNS   O\n",
              "3          NaN           have  VBP   O\n",
              "4          NaN        marched  VBN   O"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'데이터프레임 행의 개수: {len(data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5_jXF4Ah3tX",
        "outputId": "c6ff9a0e-506a-4b4f-8135-0753caa69273"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터프레임 행의 개수: 1048575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('데이터에 Null 값이 있는지 유무: ' + str(data.isnull().values.any()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KgxJ6nSnj01",
        "outputId": "fd55eca9-7e0e-4a8d-c99d-6298d2633246"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터에 Null 값이 있는지 유무: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('어떤 열에 Null 값이 있는지 출력')\n",
        "print('=' * 30)\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCp8AJavnq4q",
        "outputId": "22da7e51-b3e9-444f-d1a5-1f1fc8f05c7c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어떤 열에 Null 값이 있는지 출력\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #    1000616\n",
              "Word                0\n",
              "POS                 0\n",
              "Tag                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('sentence # 열의 중복을 제거한 값의 개수 : {}'.format(data['Sentence #'].nunique()))\n",
        "print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))\n",
        "print('Tag 열의 중복을 제거한 값의 개수 : {}'.format(data.Tag.nunique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkpycNATnyqX",
        "outputId": "96f81aec-e288-45a5-aefe-89b528a8fa39"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence # 열의 중복을 제거한 값의 개수 : 47959\n",
            "Word 열의 중복을 제거한 값의 개수 : 35178\n",
            "Tag 열의 중복을 제거한 값의 개수 : 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tag 열의 각각의 값의 개수 카운트')\n",
        "print('================================')\n",
        "print(data.groupby('Tag').size().reset_index(name='count'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q02YEVNNn5so",
        "outputId": "f37fd393-af3b-456e-9aa0-9a74a2c77bfb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag 열의 각각의 값의 개수 카운트\n",
            "================================\n",
            "      Tag   count\n",
            "0   B-art     402\n",
            "1   B-eve     308\n",
            "2   B-geo   37644\n",
            "3   B-gpe   15870\n",
            "4   B-nat     201\n",
            "5   B-org   20143\n",
            "6   B-per   16990\n",
            "7   B-tim   20333\n",
            "8   I-art     297\n",
            "9   I-eve     253\n",
            "10  I-geo    7414\n",
            "11  I-gpe     198\n",
            "12  I-nat      51\n",
            "13  I-org   16784\n",
            "14  I-per   17251\n",
            "15  I-tim    6528\n",
            "16      O  887908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.fillna(method='ffill')\n",
        "print(data.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SIZ0ogan9uL",
        "outputId": "52670b05-6abd-44b0-c90a-ab6c738fe960"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Sentence #       Word  POS Tag\n",
            "1048570  Sentence: 47959       they  PRP   O\n",
            "1048571  Sentence: 47959  responded  VBD   O\n",
            "1048572  Sentence: 47959         to   TO   O\n",
            "1048573  Sentence: 47959        the   DT   O\n",
            "1048574  Sentence: 47959     attack   NN   O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('데이터에 Null 값이 있는지 유무: ' + str(data.isnull().values.any()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0IavijBoKev",
        "outputId": "f07e3b3f-bc72-4042-a87a-0f576b883395"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터에 Null 값이 있는지 유무: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.Word = data.Word.str.lower()\n",
        "print(f'Word 열의 중복을 제거한 값의 개수: {data.Word.nunique()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwqL4-KzoQHx",
        "outputId": "6a9aae71-6d30-434d-b691-d496e738ba99"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 열의 중복을 제거한 값의 개수: 31817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du880YGNoYYj",
        "outputId": "394f4fd1-e038-4506-c3a8-0b04686dd1cb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Sentence #           Word  POS Tag\n",
            "0  Sentence: 1      thousands  NNS   O\n",
            "1  Sentence: 1             of   IN   O\n",
            "2  Sentence: 1  demonstrators  NNS   O\n",
            "3  Sentence: 1           have  VBP   O\n",
            "4  Sentence: 1        marched  VBN   O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func = lambda temp: [(w, t) for w, t in zip(temp['Word'].values.tolist(), temp['Tag'].values.tolist())]\n",
        "tagged_sentences = [t for t in data.groupby(\"Sentence #\").apply(func)]\n",
        "print(f'전체 샘플 개수: {len(tagged_sentences)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlzJ2OUJoaB4",
        "outputId": "2ebd0c21-aa16-46f8-8ed4-d986a4edf52c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 개수: 47959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tagged_sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ADg76pnov6R",
        "outputId": "9c407aca-b30b-4e82-d830-abc1df093f00"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('london', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('british', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences, ner_tags = [], []\n",
        "\n",
        "for tagged_sentence in tagged_sentences:\n",
        "  sentence, tag_info = zip(*tagged_sentence)\n",
        "  sentences.append(list(sentence))\n",
        "  ner_tags.append(list(tag_info))"
      ],
      "metadata": {
        "id": "Y8IWdkF8o2m0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[0])\n",
        "print(ner_tags[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJTcfCtqqxpJ",
        "outputId": "d7599fd4-dc10-4177-f055-f62c6c079e75"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[98])\n",
        "print(ner_tags[98])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htxpsoF4qzbT",
        "outputId": "b7f67d4d-fe5e-4a6d-acda-40cc9f3abf30"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['she', 'had', 'once', 'received', 'a', 'kidney', 'transplant', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n",
        "print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))\n",
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "vXOF_C4uq2jn",
        "outputId": "12846d21-68a0-4f54-d1f1-6c752b46c41c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 104\n",
            "샘플의 평균 길이 : 21.863988\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 단어를 사용하며 인덱스 1에는 단어 'OOV'를 할당.\n",
        "src_tokenizer = Tokenizer(oov_token='OOV')\n",
        "# 태깅 정보들은 내부적으로 대문자를 유지한 채 저장\n",
        "tar_tokenizer = Tokenizer(lower=False)\n",
        "\n",
        "src_tokenizer.fit_on_texts(sentences)\n",
        "tar_tokenizer.fit_on_texts(ner_tags)"
      ],
      "metadata": {
        "id": "PoUcw34tq4Ug"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(src_tokenizer.word_index) + 1\n",
        "tag_size = len(tar_tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
        "print('개체명 태깅 정보 집합의 크기 : {}'.format(tag_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4bBtLYwq-0q",
        "outputId": "6f6e949b-0b8b-4879-ee4e-57392501e553"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 31819\n",
            "개체명 태깅 정보 집합의 크기 : 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'단어 OOV의 인덱스: {src_tokenizer.word_index[\"OOV\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5RyAboQrAwq",
        "outputId": "d22ab589-ebc3-4648-fd37-cc8c53123496"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 OOV의 인덱스: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = src_tokenizer.texts_to_sequences(sentences)\n",
        "y_data = tar_tokenizer.texts_to_sequences(ner_tags)"
      ],
      "metadata": {
        "id": "fuLntkFfrljc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_data[0])\n",
        "print(y_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Rkt0PaLrp9I",
        "outputId": "cecb56bf-6e71-4565-a024-149613e92938"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[254, 6, 967, 16, 1795, 238, 468, 7, 523, 2, 129, 5, 61, 9, 571, 2, 833, 6, 186, 90, 22, 15, 56, 3]\n",
            "[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = src_tokenizer.word_index\n",
        "index_to_word = src_tokenizer.index_word\n",
        "ner_to_index = tar_tokenizer.word_index\n",
        "index_to_ner = tar_tokenizer.index_word\n",
        "index_to_ner[0] = 'PAD'\n",
        "\n",
        "print(index_to_ner)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0UjxCt6rrF5",
        "outputId": "9829fa2e-2b6f-4da9-b2ad-afa53b9dd0e0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'O', 2: 'B-geo', 3: 'B-tim', 4: 'B-org', 5: 'I-per', 6: 'B-per', 7: 'I-org', 8: 'B-gpe', 9: 'I-geo', 10: 'I-tim', 11: 'B-art', 12: 'B-eve', 13: 'I-art', 14: 'I-eve', 15: 'B-nat', 16: 'I-gpe', 17: 'I-nat', 0: 'PAD'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = []\n",
        "for index in X_data[0]:\n",
        "  decoded.append(index_to_word[index])\n",
        "\n",
        "print(f'기존의 문장: {sentences[0]}')\n",
        "print(f'디코딩 문장: {decoded}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0bKXntmr7l0",
        "outputId": "985b7ff2-c64f-4b65-bb6d-02f07128f0c9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "기존의 문장: ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
            "디코딩 문장: ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 70\n",
        "X_data = pad_sequences(X_data, padding='post', maxlen=max_len)\n",
        "y_data = pad_sequences(y_data, padding='post', maxlen=max_len)"
      ],
      "metadata": {
        "id": "kw0zBen3sHGV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train_int, y_test_int = train_test_split(X_data, y_data, test_size=.2, random_state=777)"
      ],
      "metadata": {
        "id": "RFaLRlP-sNDd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train_int, num_classes=tag_size)\n",
        "y_test = to_categorical(y_test_int, num_classes=tag_size)"
      ],
      "metadata": {
        "id": "g167ZJ--sUeW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
        "print('훈련 샘플 레이블(정수 인코딩)의 크기 : {}'.format(y_train_int.shape))\n",
        "print('훈련 샘플 레이블(원-핫 인코딩)의 크기 : {}'.format(y_train.shape))\n",
        "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
        "print('테스트 샘플 레이블(정수 인코딩)의 크기 : {}'.format(y_test_int.shape))\n",
        "print('테스트 샘플 레이블(원-핫 인코딩)의 크기 : {}'.format(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRw1od8Vsca3",
        "outputId": "3339bc7c-b4cf-4599-9f57-e29406a3e0cf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 샘플 문장의 크기 : (38367, 70)\n",
            "훈련 샘플 레이블(정수 인코딩)의 크기 : (38367, 70)\n",
            "훈련 샘플 레이블(원-핫 인코딩)의 크기 : (38367, 70, 18)\n",
            "테스트 샘플 문장의 크기 : (9592, 70)\n",
            "테스트 샘플 레이블(정수 인코딩)의 크기 : (9592, 70)\n",
            "테스트 샘플 레이블(원-핫 인코딩)의 크기 : (9592, 70, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 양방향 LSTM을 이용한 개체명 인식"
      ],
      "metadata": {
        "id": "nNOi76dduyeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "embedding_dim=128\n",
        "hidden_units=256\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(hidden_units, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(tag_size, activation=('softmax'))))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=128, epochs=6, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNJysUBysd4w",
        "outputId": "1f6dfc62-83e4-42d7-e563-153e20349715"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "270/270 [==============================] - 374s 1s/step - loss: 0.1756 - accuracy: 0.8733 - val_loss: 0.0818 - val_accuracy: 0.9273\n",
            "Epoch 2/6\n",
            "270/270 [==============================] - 353s 1s/step - loss: 0.0541 - accuracy: 0.9505 - val_loss: 0.0475 - val_accuracy: 0.9544\n",
            "Epoch 3/6\n",
            "270/270 [==============================] - 361s 1s/step - loss: 0.0361 - accuracy: 0.9653 - val_loss: 0.0426 - val_accuracy: 0.9585\n",
            "Epoch 4/6\n",
            "270/270 [==============================] - 364s 1s/step - loss: 0.0295 - accuracy: 0.9706 - val_loss: 0.0423 - val_accuracy: 0.9593\n",
            "Epoch 5/6\n",
            "270/270 [==============================] - 361s 1s/step - loss: 0.0253 - accuracy: 0.9742 - val_loss: 0.0433 - val_accuracy: 0.9592\n",
            "Epoch 6/6\n",
            "270/270 [==============================] - 356s 1s/step - loss: 0.0222 - accuracy: 0.9772 - val_loss: 0.0477 - val_accuracy: 0.9581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 13\n",
        "y_predicated = model.predict(np.array([X_test[i]]))\n",
        "y_predicated = np.argmax(y_predicated, axis=-1)\n",
        "labels = np.argmax(y_test[i], -1)\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for word,tag, pred in zip(X_test[i], labels, y_predicated[0]):\n",
        "  if word != 0:\n",
        "    print(\"{:17}: {:7} {}\".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzTGqWvk5QTH",
        "outputId": "82e08777-3181-4268-da47-75e8299a3f59"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "the              : O       O\n",
            "statement        : O       O\n",
            "came             : O       O\n",
            "as               : O       O\n",
            "u.n.             : B-org   B-org\n",
            "secretary-general: I-org   I-org\n",
            "kofi             : B-per   B-per\n",
            "annan            : I-per   I-per\n",
            "met              : O       O\n",
            "with             : O       O\n",
            "officials        : O       O\n",
            "in               : O       O\n",
            "amman            : B-geo   O\n",
            "to               : O       O\n",
            "discuss          : O       O\n",
            "wednesday        : B-tim   B-tim\n",
            "'s               : O       O\n",
            "attacks          : O       O\n",
            ".                : O       O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## F1-score"
      ],
      "metadata": {
        "id": "ExDX-qFB5xTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['B-PER', 'I-PER', 'O', 'O', 'B-MISC', 'O','O','O','O','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O','O','B-MISC','I-MISC','I-MISC','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O']\n",
        "predicted = ['O'] * len(labels) \n",
        "print('예측값 :',predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfU274hI5pOW",
        "outputId": "1544830c-768e-4418-af82-29e1b63d3cea"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측값 : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hit = 0 # 정답 개수\n",
        "for tag, pred in zip(labels, predicted):\n",
        "    if tag == pred:\n",
        "        hit +=1 # 정답인 경우에만 +1\n",
        "accuracy = hit/len(labels) # 정답 개수를 총 개수로 나눈다.\n",
        "print(\"정확도: {:.1%}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2GHUlUO5vDx",
        "outputId": "789637b7-8e72-4efd-fece-e85e2a37dcac"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 74.4%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaq6fCCS5wOP",
        "outputId": "4c0de650-38dc-4081-bd1f-461f158f876e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▌                        | 10 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20 kB 20.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 43 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=dd9a52991d92dec82a826815d0cf00cec3ecf120b3dd9270aaf29cf57a9ebd68\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import classification_report\n",
        "print(classification_report([labels], [predicted]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Lnw6LvV7wfj",
        "outputId": "f90587b8-62d1-4f4c-9a9c-8be84fabe0f0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        MISC       0.00      0.00      0.00         2\n",
            "         PER       0.00      0.00      0.00         3\n",
            "\n",
            "   micro avg       0.00      0.00      0.00         5\n",
            "   macro avg       0.00      0.00      0.00         5\n",
            "weighted avg       0.00      0.00      0.00         5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['B-PER', 'I-PER', 'O', 'O', 'B-MISC', 'O','O','O','O','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O','O','B-MISC','I-MISC','I-MISC','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O']\n",
        "predicted = ['B-PER', 'I-PER', 'O', 'O', 'B-MISC', 'O','O','O','O','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O']\n",
        "\n",
        "print(classification_report([labels], [predicted]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG1SrAjA8Bsl",
        "outputId": "8671558b-2d49-460a-8625-796863919e7d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        MISC       1.00      0.50      0.67         2\n",
            "         PER       1.00      0.67      0.80         3\n",
            "\n",
            "   micro avg       1.00      0.60      0.75         5\n",
            "   macro avg       1.00      0.58      0.73         5\n",
            "weighted avg       1.00      0.60      0.75         5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## F1-score로 성능 측정하기"
      ],
      "metadata": {
        "id": "mZyL5M3r8FZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import f1_score, classification_report\n",
        "\n",
        "def sequences_to_tag(sequences):\n",
        "  result = []\n",
        "  for sequence in sequences:\n",
        "    word_sequence = []\n",
        "    for pred in sequence:\n",
        "      pred_index = np.argmax(pred)\n",
        "      word_sequence.append(index_to_ner[pred_index].replace(\"PAD\", \"O\"))\n",
        "    result.append(word_sequence)\n",
        "  return result\n",
        "\n",
        "y_predicated = model.predict([X_test])\n",
        "pred_tags = sequences_to_tag(y_predicated)\n",
        "test_tags = sequences_to_tag(y_test)\n",
        "\n",
        "print(f'F1-score: {f1_score(test_tags, pred_tags):.1%}')\n",
        "print(classification_report(test_tags, pred_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liNyh13B8EG1",
        "outputId": "cf3cd15a-136e-4493-817a-565251d889b4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 78.2%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.30      0.05      0.08        63\n",
            "         eve       0.39      0.27      0.32        52\n",
            "         geo       0.84      0.82      0.83      7620\n",
            "         gpe       0.95      0.95      0.95      3145\n",
            "         nat       0.40      0.22      0.28        37\n",
            "         org       0.60      0.53      0.56      4033\n",
            "         per       0.73      0.70      0.71      3545\n",
            "         tim       0.86      0.84      0.85      4067\n",
            "\n",
            "   micro avg       0.80      0.76      0.78     22562\n",
            "   macro avg       0.63      0.55      0.57     22562\n",
            "weighted avg       0.79      0.76      0.78     22562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BiLSTM-CRF를 이용한 개체명 인식"
      ],
      "metadata": {
        "id": "Dk8DfqLj_fJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CRF 층 설치하기"
      ],
      "metadata": {
        "id": "pLSbO9CpAshz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-crf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRRrTgrm_hOK",
        "outputId": "1e89013a-48f4-4845-d0fa-9de4c5006bd5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-crf\n",
            "  Downloading keras_crf-0.3.0-py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-crf) (2.8.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 23.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.6.3)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 48.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.15.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (13.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.44.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.13.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (3.17.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.21.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (0.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (0.24.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (3.10.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->keras-crf) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras-crf) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-crf) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-crf) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-crf) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-crf) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-crf) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-crf) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-crf) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (4.11.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (3.2.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->keras-crf) (2.7.1)\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow-addons, keras-crf\n",
            "Successfully installed keras-crf-0.3.0 tensorflow-addons-0.16.1 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BiLSTM-CRF를 이용한 개체명 인식"
      ],
      "metadata": {
        "id": "pLMo7nkpA3Hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input, Bidirectional, TimeDistributed, Embedding, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras_crf import CRFModel\n",
        "from seqeval.metrics import f1_score, classification_report"
      ],
      "metadata": {
        "id": "Hmys374oAt8D"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "hidden_units = 64\n",
        "dropout_ratio = 0.3\n",
        "\n",
        "sequence_input = Input(shape=(max_len,),dtype=tf.int32, name='sequence_input')\n",
        "\n",
        "model_embedding = Embedding(input_dim=vocab_size,\n",
        "                            output_dim=embedding_dim,\n",
        "                            input_length=max_len)(sequence_input)\n",
        "\n",
        "model_bilstm = Bidirectional(LSTM(units=hidden_units, return_sequences=True))(model_embedding)\n",
        "\n",
        "model_dropout = TimeDistributed(Dropout(dropout_ratio))(model_bilstm)\n",
        "\n",
        "model_dense = TimeDistributed(Dense(tag_size, activation='relu'))(model_dropout)\n",
        "\n",
        "base = Model(inputs=sequence_input, outputs=model_dense)\n",
        "model = CRFModel(base, tag_size)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), metrics='accuracy')"
      ],
      "metadata": {
        "id": "zz3GIa_DBT2M"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('bilstm_crf/cp.ckpt', monitor='val_decode_sequence_accuracy', mode='max', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "history = model.fit(X_train, y_train_int, batch_size=128, epochs=15, validation_split=0.1, callbacks=[mc, es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jzza0rw5Cn20",
        "outputId": "9d9ab1ba-58a1-4ac8-fc78-69dc99ab098b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9129 - loss: 29.1784\n",
            "Epoch 1: val_decode_sequence_accuracy improved from -inf to 0.96331, saving model to bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 125s 429ms/step - decode_sequence_accuracy: 0.9129 - loss: 29.1021 - val_decode_sequence_accuracy: 0.9633 - val_loss: 9.5220\n",
            "Epoch 2/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9725 - loss: 6.4831\n",
            "Epoch 2: val_decode_sequence_accuracy improved from 0.96331 to 0.97973, saving model to bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 101s 375ms/step - decode_sequence_accuracy: 0.9725 - loss: 6.4765 - val_decode_sequence_accuracy: 0.9797 - val_loss: 4.8675\n",
            "Epoch 3/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9821 - loss: 3.6812\n",
            "Epoch 3: val_decode_sequence_accuracy improved from 0.97973 to 0.98265, saving model to bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 100s 372ms/step - decode_sequence_accuracy: 0.9821 - loss: 3.6805 - val_decode_sequence_accuracy: 0.9827 - val_loss: 3.6843\n",
            "Epoch 4/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9855 - loss: 2.7397\n",
            "Epoch 4: val_decode_sequence_accuracy improved from 0.98265 to 0.98393, saving model to bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 102s 379ms/step - decode_sequence_accuracy: 0.9855 - loss: 2.7411 - val_decode_sequence_accuracy: 0.9839 - val_loss: 3.2118\n",
            "Epoch 5/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9874 - loss: 2.2208\n",
            "Epoch 5: val_decode_sequence_accuracy improved from 0.98393 to 0.98478, saving model to bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 102s 377ms/step - decode_sequence_accuracy: 0.9874 - loss: 2.2210 - val_decode_sequence_accuracy: 0.9848 - val_loss: 3.0101\n",
            "Epoch 6/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9888 - loss: 1.8653\n",
            "Epoch 6: val_decode_sequence_accuracy improved from 0.98478 to 0.98502, saving model to bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 101s 373ms/step - decode_sequence_accuracy: 0.9888 - loss: 1.8663 - val_decode_sequence_accuracy: 0.9850 - val_loss: 2.9512\n",
            "Epoch 7/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9899 - loss: 1.6169\n",
            "Epoch 7: val_decode_sequence_accuracy improved from 0.98502 to 0.98504, saving model to bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 104s 385ms/step - decode_sequence_accuracy: 0.9899 - loss: 1.6156 - val_decode_sequence_accuracy: 0.9850 - val_loss: 3.0888\n",
            "Epoch 8/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9907 - loss: 1.4087\n",
            "Epoch 8: val_decode_sequence_accuracy did not improve from 0.98504\n",
            "270/270 [==============================] - 104s 386ms/step - decode_sequence_accuracy: 0.9907 - loss: 1.4091 - val_decode_sequence_accuracy: 0.9847 - val_loss: 3.0919\n",
            "Epoch 9/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9914 - loss: 1.2536\n",
            "Epoch 9: val_decode_sequence_accuracy did not improve from 0.98504\n",
            "270/270 [==============================] - 104s 387ms/step - decode_sequence_accuracy: 0.9914 - loss: 1.2542 - val_decode_sequence_accuracy: 0.9849 - val_loss: 3.3130\n",
            "Epoch 10/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9921 - loss: 1.1173\n",
            "Epoch 10: val_decode_sequence_accuracy did not improve from 0.98504\n",
            "270/270 [==============================] - 106s 391ms/step - decode_sequence_accuracy: 0.9921 - loss: 1.1157 - val_decode_sequence_accuracy: 0.9844 - val_loss: 3.5489\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('bilstm_crf/cp.ckpt')\n",
        "\n",
        "i = 13\n",
        "y_predicted = model.predict(np.array([X_test[i]]))[0]\n",
        "labels = np.argmax(y_test[i], -1)\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for word, tag, pred in zip(X_test[i], labels, y_predicted[0]):\n",
        "    if word != 0: # PAD값은 제외함.\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAwULtC_CzuC",
        "outputId": "460164d3-c47b-4327-fe36-050006ff5bc7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "the              : O       O\n",
            "statement        : O       O\n",
            "came             : O       O\n",
            "as               : O       O\n",
            "u.n.             : B-org   B-org\n",
            "secretary-general: I-org   I-org\n",
            "kofi             : B-per   B-per\n",
            "annan            : I-per   I-per\n",
            "met              : O       O\n",
            "with             : O       O\n",
            "officials        : O       O\n",
            "in               : O       O\n",
            "amman            : B-geo   B-geo\n",
            "to               : O       O\n",
            "discuss          : O       O\n",
            "wednesday        : B-tim   B-tim\n",
            "'s               : O       O\n",
            "attacks          : O       O\n",
            ".                : O       O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicated = model.predict(X_test)[0]"
      ],
      "metadata": {
        "id": "f37SGC6_DCva"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_predicated[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ozuybj5DFzz",
        "outputId": "411d7f28-1533-4a60-b7ec-9520e0222ed6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  3 10  1  4  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 1  1  1  1  1  1  3  1  1  1  1  1  1  1  2  9  9  1  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sequences_to_tag_for_crf(sequences):\n",
        "  result = []\n",
        "  for sequence in sequences:\n",
        "    word_sequence  = []\n",
        "    for pred_index in sequence:\n",
        "      word_sequence.append(index_to_ner[pred_index].replace(\"PAD\", \"O\"))\n",
        "    result.append(word_sequence)\n",
        "  return result\n",
        "\n",
        "pred_tags = sequences_to_tag_for_crf(y_predicated)\n",
        "test_tags = sequences_to_tag(y_test)\n",
        "\n",
        "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n",
        "print(classification_report(test_tags, pred_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzAuzZHiDIXd",
        "outputId": "74c7973c-ce61-4cad-fa76-c3892b88e257"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 79.5%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        63\n",
            "         eve       0.00      0.00      0.00        52\n",
            "         geo       0.84      0.83      0.83      7620\n",
            "         gpe       0.94      0.94      0.94      3145\n",
            "         nat       0.44      0.11      0.17        37\n",
            "         org       0.64      0.59      0.61      4033\n",
            "         per       0.78      0.71      0.74      3545\n",
            "         tim       0.88      0.81      0.84      4067\n",
            "\n",
            "   micro avg       0.82      0.77      0.79     22562\n",
            "   macro avg       0.57      0.50      0.52     22562\n",
            "weighted avg       0.81      0.77      0.79     22562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문자 임베딩(Character Embedding) 활용하기\n",
        "\n",
        "https://wikidocs.net/147299"
      ],
      "metadata": {
        "id": "jS4_A2Y8MKnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문자 임베딩(Char Embedding)을 위한 전처리"
      ],
      "metadata": {
        "id": "uV1nZ0EbMPyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = list(set(data[\"Word\"].values))\n",
        "chars = set(w_i for w in words for w_i in w)\n",
        "chars = sorted(list(chars))\n",
        "print('문자 집합: ', chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cun0Dv4tMRM2",
        "outputId": "d03b53df-4ffe-4b70-d115-15bfdedaebca"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합:  ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '\\x85', '\\x91', '\\x92', '\\x93', '\\x94', '\\x96', '\\x97', '\\xa0', '°', 'é', 'ë', 'ö', 'ü']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index = {c: i + 2 for i, c in enumerate(chars)}\n",
        "char_to_index[\"OOV\"] = 1\n",
        "char_to_index[\"PAD\"] = 0\n",
        "\n",
        "index_to_char = {}\n",
        "\n",
        "for key, value in char_to_index.items():\n",
        "  index_to_char[value] = key"
      ],
      "metadata": {
        "id": "yJSsbR7QMcfF"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len_char = 15\n",
        "\n",
        "def padding_char_indice(char_index, max_len_char):\n",
        "  return pad_sequences(char_index, maxlen=max_len_char, padding='post', value=0)\n",
        "\n",
        "def integer_coding(sentences):\n",
        "  char_data = []\n",
        "  for ts in sentences:\n",
        "    word_indice = [word_to_index[t] for t in ts]\n",
        "    char_indice = [[char_to_index[char] for char in t] for t in ts]\n",
        "    char_indice = padding_char_indice(char_indice, max_len_char)\n",
        "\n",
        "    for chars_to_token in char_indice:\n",
        "      if len(chars_to_token) > max_len_char:\n",
        "        continue\n",
        "    \n",
        "    char_data.append(char_indice)\n",
        "  return char_data\n",
        "\n",
        "X_char_data = integer_coding(sentences)"
      ],
      "metadata": {
        "id": "i1JXqEJ_M3qd"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('기존 문장: ', sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAZQztD7NpKr",
        "outputId": "776e8cc3-8c18-4207-f47c-c607a82e86d9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "기존 문장:  ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 단위 정수 인코딩:')\n",
        "print(X_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stZJAeieNtVF",
        "outputId": "2522a300-6dc8-4684-ac26-dbb687ae3e29"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 단위 정수 인코딩:\n",
            "[ 254    6  967   16 1795  238  468    7  523    2  129    5   61    9\n",
            "  571    2  833    6  186   90   22   15   56    3    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자 단위 정수 인코딩\n",
        "print('문자 단위 정수 인코딩 :')\n",
        "print(X_char_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3NyMwM_NyJ6",
        "outputId": "2a61a5d1-7372-4722-e7a8-c99351edbf0f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 단위 정수 인코딩 :\n",
            "[[53 41 48 54 52 34 47 37 52  0  0  0  0  0  0]\n",
            " [48 39  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [37 38 46 48 47 52 53 51 34 53 48 51 52  0  0]\n",
            " [41 34 55 38  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [46 34 51 36 41 38 37  0  0  0  0  0  0  0  0]\n",
            " [53 41 51 48 54 40 41  0  0  0  0  0  0  0  0]\n",
            " [45 48 47 37 48 47  0  0  0  0  0  0  0  0  0]\n",
            " [53 48  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [49 51 48 53 38 52 53  0  0  0  0  0  0  0  0]\n",
            " [53 41 38  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [56 34 51  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [42 47  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [42 51 34 50  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [34 47 37  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [37 38 46 34 47 37  0  0  0  0  0  0  0  0  0]\n",
            " [53 41 38  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [56 42 53 41 37 51 34 56 34 45  0  0  0  0  0]\n",
            " [48 39  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [35 51 42 53 42 52 41  0  0  0  0  0  0  0  0]\n",
            " [53 51 48 48 49 52  0  0  0  0  0  0  0  0  0]\n",
            " [39 51 48 46  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [53 41 34 53  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [36 48 54 47 53 51 58  0  0  0  0  0  0  0  0]\n",
            " [14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_char_data = pad_sequences(X_char_data, maxlen=max_len, padding='post', value=0)"
      ],
      "metadata": {
        "id": "I6KBs3fUN23a"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_char_train, X_char_test, _, _ = train_test_split(X_char_data, y_data, test_size=.2, random_state=777)\n",
        "\n",
        "X_char_train = np.array(X_char_train)\n",
        "X_char_test = np.array(X_char_test)"
      ],
      "metadata": {
        "id": "TC3zhAfsOA3R"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(index_to_word[150])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PIWpfCJOLYs",
        "outputId": "a5266232-a78b-4a71-87a2-7d8e9aded53e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "soldiers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' '.join([index_to_char[index] for index in X_char_train[0][0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cbo4aW5RONOL",
        "outputId": "307edb58-88f3-4210-d17a-a8633738da18"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s o l d i e r s PAD PAD PAD PAD PAD PAD PAD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
        "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
        "print('훈련 샘플 char 데이터의 크기 : {}'.format(X_char_train.shape))\n",
        "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
        "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyqO2g6wOT28",
        "outputId": "802054fc-554c-40f7-8133-6806782690c5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 샘플 문장의 크기 : (38367, 70)\n",
            "훈련 샘플 레이블의 크기 : (38367, 70, 18)\n",
            "훈련 샘플 char 데이터의 크기 : (38367, 70, 15)\n",
            "테스트 샘플 문장의 크기 : (9592, 70)\n",
            "테스트 샘플 레이블의 크기 : (9592, 70, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BiLSTM-CNN을 이용한 개체명 인식"
      ],
      "metadata": {
        "id": "MnArfZFFOYeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Input, TimeDistributed, Dropout, concatenate, Bidirectional, LSTM, Conv1D, Dense, MaxPooling1D, Flatten\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.initializers import RandomUniform\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from seqeval.metrics import f1_score, classification_report\n",
        "from keras_crf import CRFModel"
      ],
      "metadata": {
        "id": "pW2E_8LFOXWz"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "char_embedding_dim = 64\n",
        "dropout_ratio = 0.5\n",
        "hidden_units = 256\n",
        "num_filters = 30\n",
        "kernel_size = 3\n",
        "\n",
        "# 단어 임베딩\n",
        "word_ids = Input(shape=(None,),dtype='int32', name='words_input')\n",
        "word_embeddings = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(word_ids)\n",
        "\n",
        "# char 임베딩\n",
        "char_ids = Input(shape=(None, max_len_char,), name='char_input')\n",
        "embed_char_out = TimeDistributed(Embedding(len(char_to_index), char_embedding_dim, embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(char_ids)\n",
        "dropout = Dropout(dropout_ratio)(embed_char_out)\n",
        "\n",
        "# char 임베딩에 대해서는 Conv1D 수행\n",
        "conv1d_out = TimeDistributed(Conv1D(kernel_size=kernel_size, filters=num_filters, padding='same', activation='tanh', strides=1))(dropout)\n",
        "maxpool_out = TimeDistributed(MaxPooling1D(max_len_char))(conv1d_out)\n",
        "char_embeddings = TimeDistributed(Flatten())(maxpool_out)\n",
        "char_embeddings = Dropout(dropout_ratio)(char_embeddings)\n",
        "\n",
        "# char 임베딩을 Conv1D 수행한 뒤에 단어 임베딩과 연결\n",
        "output = concatenate([word_embeddings, char_embeddings])\n",
        "\n",
        "# 연결한 벡터를 가지고 문장의 길이만큼 LSTM을 수행\n",
        "output = Bidirectional(LSTM(hidden_units, return_sequences=True, dropout=dropout_ratio))(output)\n",
        "\n",
        "# 출력층\n",
        "output = TimeDistributed(Dense(tag_size, activation='softmax'))(output)\n",
        "\n",
        "model = Model(inputs=[word_ids, char_ids], outputs=[output])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='nadam',  metrics=['acc'])"
      ],
      "metadata": {
        "id": "gzZj4pDGQxFw"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('bilstm_cnn.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "history = model.fit([X_train, X_char_train], y_train, batch_size=128, epochs=15, validation_split=0.1, verbose=1, callbacks=[es, mc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrR9AV_VSGGK",
        "outputId": "1ffa8c52-81e5-4599-a9c5-fb58f50d4f14"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.2083 - acc: 0.9480\n",
            "Epoch 1: val_acc improved from -inf to 0.97708, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 453s 2s/step - loss: 0.2083 - acc: 0.9480 - val_loss: 0.0826 - val_acc: 0.9771\n",
            "Epoch 2/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0635 - acc: 0.9818\n",
            "Epoch 2: val_acc improved from 0.97708 to 0.98441, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 442s 2s/step - loss: 0.0635 - acc: 0.9818 - val_loss: 0.0526 - val_acc: 0.9844\n",
            "Epoch 3/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0455 - acc: 0.9867\n",
            "Epoch 3: val_acc improved from 0.98441 to 0.98639, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 450s 2s/step - loss: 0.0455 - acc: 0.9867 - val_loss: 0.0453 - val_acc: 0.9864\n",
            "Epoch 4/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0383 - acc: 0.9885\n",
            "Epoch 4: val_acc improved from 0.98639 to 0.98701, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 445s 2s/step - loss: 0.0383 - acc: 0.9885 - val_loss: 0.0431 - val_acc: 0.9870\n",
            "Epoch 5/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0338 - acc: 0.9897\n",
            "Epoch 5: val_acc improved from 0.98701 to 0.98745, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 456s 2s/step - loss: 0.0338 - acc: 0.9897 - val_loss: 0.0407 - val_acc: 0.9875\n",
            "Epoch 6/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0307 - acc: 0.9905\n",
            "Epoch 6: val_acc improved from 0.98745 to 0.98774, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 437s 2s/step - loss: 0.0307 - acc: 0.9905 - val_loss: 0.0403 - val_acc: 0.9877\n",
            "Epoch 7/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0284 - acc: 0.9911\n",
            "Epoch 7: val_acc did not improve from 0.98774\n",
            "270/270 [==============================] - 442s 2s/step - loss: 0.0284 - acc: 0.9911 - val_loss: 0.0408 - val_acc: 0.9875\n",
            "Epoch 8/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0263 - acc: 0.9917\n",
            "Epoch 8: val_acc improved from 0.98774 to 0.98775, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 438s 2s/step - loss: 0.0263 - acc: 0.9917 - val_loss: 0.0407 - val_acc: 0.9878\n",
            "Epoch 9/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0248 - acc: 0.9921\n",
            "Epoch 9: val_acc did not improve from 0.98775\n",
            "270/270 [==============================] - 438s 2s/step - loss: 0.0248 - acc: 0.9921 - val_loss: 0.0406 - val_acc: 0.9876\n",
            "Epoch 10/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0231 - acc: 0.9926\n",
            "Epoch 10: val_acc improved from 0.98775 to 0.98777, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 436s 2s/step - loss: 0.0231 - acc: 0.9926 - val_loss: 0.0412 - val_acc: 0.9878\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('bilstm_cnn.h5')\n",
        "\n",
        "i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
        "# 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
        "y_predicted = model.predict([np.array([X_test[i]]), np.array([X_char_test[i]])])\n",
        "\n",
        "y_predicted = np.argmax(y_predicted, axis=-1) # 확률 벡터를 정수 인코딩으로 변경.\n",
        "labels = np.argmax(y_test[i], -1) # 원-핫 인코딩을 정수 인코딩으로 변경.\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for word, tag, pred in zip(X_test[i], labels, y_predicted[0]):\n",
        "    if word != 0: # PAD값은 제외함.\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqmcYvvQSHjJ",
        "outputId": "96cb225e-da77-4543-ec45-eaee77566982"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "the              : O       O\n",
            "statement        : O       O\n",
            "came             : O       O\n",
            "as               : O       O\n",
            "u.n.             : B-org   B-org\n",
            "secretary-general: I-org   I-org\n",
            "kofi             : B-per   B-per\n",
            "annan            : I-per   I-per\n",
            "met              : O       O\n",
            "with             : O       O\n",
            "officials        : O       O\n",
            "in               : O       O\n",
            "amman            : B-geo   B-geo\n",
            "to               : O       O\n",
            "discuss          : O       O\n",
            "wednesday        : B-tim   B-tim\n",
            "'s               : O       O\n",
            "attacks          : O       O\n",
            ".                : O       O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict([X_test, X_char_test])\n",
        "pred_tags = sequences_to_tag(y_predicted)\n",
        "test_tags = sequences_to_tag(y_test)\n",
        "\n",
        "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n",
        "print(classification_report(test_tags, pred_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8sDJIftTCZW",
        "outputId": "e4a6ff50-4b58-4906-97f3-6d0c739507aa"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 79.5%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        63\n",
            "         eve       0.70      0.27      0.39        52\n",
            "         geo       0.84      0.84      0.84      7620\n",
            "         gpe       0.95      0.95      0.95      3145\n",
            "         nat       0.48      0.32      0.39        37\n",
            "         org       0.61      0.57      0.59      4033\n",
            "         per       0.73      0.74      0.73      3545\n",
            "         tim       0.87      0.84      0.85      4067\n",
            "\n",
            "   micro avg       0.80      0.79      0.79     22562\n",
            "   macro avg       0.65      0.57      0.59     22562\n",
            "weighted avg       0.80      0.79      0.79     22562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BiLSTM-CNN-CRF"
      ],
      "metadata": {
        "id": "xjukTVIpTEkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "char_embedding_dim = 64\n",
        "dropout_ratio = 0.5\n",
        "hidden_units = 256\n",
        "num_filters = 30\n",
        "kernel_size = 3\n",
        "\n",
        "# 단어 임베딩\n",
        "word_ids = Input(shape=(None,),dtype='int32', name='words_input')\n",
        "word_embeddings = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(word_ids)\n",
        "\n",
        "# char 임베딩\n",
        "char_ids = Input(shape=(None, max_len_char,), name='char_input')\n",
        "embed_char_out = TimeDistributed(Embedding(len(char_to_index), char_embedding_dim, embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(char_ids)\n",
        "dropout = Dropout(dropout_ratio)(embed_char_out)\n",
        "\n",
        "# char 임베딩에 대해서는 Conv1D 수행\n",
        "conv1d_out = TimeDistributed(Conv1D(kernel_size=kernel_size, filters=num_filters, padding='same',activation='tanh', strides=1))(dropout)\n",
        "maxpool_out=TimeDistributed(MaxPooling1D(max_len_char))(conv1d_out)\n",
        "char_embeddings = TimeDistributed(Flatten())(maxpool_out)\n",
        "char_embeddings = Dropout(dropout_ratio)(char_embeddings)\n",
        "\n",
        "# char 임베딩을 Conv1D 수행한 뒤에 단어 임베딩과 연결\n",
        "output = concatenate([word_embeddings, char_embeddings])\n",
        "\n",
        "# 연결한 벡터를 가지고 문장의 길이만큼 LSTM을 수행\n",
        "output = Bidirectional(LSTM(hidden_units, return_sequences=True, dropout=dropout_ratio))(output)\n",
        "\n",
        "# 출력층\n",
        "output = TimeDistributed(Dense(tag_size, activation='relu'))(output)\n",
        "\n",
        "base = Model(inputs=[word_ids, char_ids], outputs=[output])\n",
        "model = CRFModel(base, tag_size)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), metrics='accuracy')\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('bilstm_cnn_crf/cp.ckpt', monitor='val_decode_sequence_accuracy', mode='max', verbose=1, save_best_only=True, save_weights_only=True)"
      ],
      "metadata": {
        "id": "aaTW53G6TDjW"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([X_train, X_char_train], y_train_int, batch_size=128, epochs=15, validation_split=0.1, callbacks=[mc, es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXaPoZSjTI9c",
        "outputId": "4cc3151f-4dee-480e-a8ca-975c0c64e0d4"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9361 - loss: 17.8648\n",
            "Epoch 1: val_decode_sequence_accuracy improved from -inf to 0.97157, saving model to bilstm_cnn_crf/cp.ckpt\n",
            "270/270 [==============================] - 455s 2s/step - decode_sequence_accuracy: 0.9361 - loss: 17.8224 - val_decode_sequence_accuracy: 0.9716 - val_loss: 6.6363\n",
            "Epoch 2/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9801 - loss: 4.4281\n",
            "Epoch 2: val_decode_sequence_accuracy improved from 0.97157 to 0.98380, saving model to bilstm_cnn_crf/cp.ckpt\n",
            "270/270 [==============================] - 446s 2s/step - decode_sequence_accuracy: 0.9801 - loss: 4.4232 - val_decode_sequence_accuracy: 0.9838 - val_loss: 3.4418\n",
            "Epoch 3/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9860 - loss: 2.8396\n",
            "Epoch 3: val_decode_sequence_accuracy improved from 0.98380 to 0.98547, saving model to bilstm_cnn_crf/cp.ckpt\n",
            "270/270 [==============================] - 444s 2s/step - decode_sequence_accuracy: 0.9860 - loss: 2.8410 - val_decode_sequence_accuracy: 0.9855 - val_loss: 2.8025\n",
            "Epoch 4/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9881 - loss: 2.2578\n",
            "Epoch 4: val_decode_sequence_accuracy improved from 0.98547 to 0.98628, saving model to bilstm_cnn_crf/cp.ckpt\n",
            "270/270 [==============================] - 452s 2s/step - decode_sequence_accuracy: 0.9881 - loss: 2.2576 - val_decode_sequence_accuracy: 0.9863 - val_loss: 2.5911\n",
            "Epoch 5/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9893 - loss: 1.9410\n",
            "Epoch 5: val_decode_sequence_accuracy did not improve from 0.98628\n",
            "270/270 [==============================] - 439s 2s/step - decode_sequence_accuracy: 0.9893 - loss: 1.9406 - val_decode_sequence_accuracy: 0.9862 - val_loss: 2.6555\n",
            "Epoch 6/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9899 - loss: 1.7518\n",
            "Epoch 6: val_decode_sequence_accuracy improved from 0.98628 to 0.98641, saving model to bilstm_cnn_crf/cp.ckpt\n",
            "270/270 [==============================] - 430s 2s/step - decode_sequence_accuracy: 0.9899 - loss: 1.7524 - val_decode_sequence_accuracy: 0.9864 - val_loss: 2.5587\n",
            "Epoch 7/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9905 - loss: 1.5734\n",
            "Epoch 7: val_decode_sequence_accuracy did not improve from 0.98641\n",
            "270/270 [==============================] - 437s 2s/step - decode_sequence_accuracy: 0.9905 - loss: 1.5719 - val_decode_sequence_accuracy: 0.9863 - val_loss: 2.5293\n",
            "Epoch 8/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9909 - loss: 1.4464\n",
            "Epoch 8: val_decode_sequence_accuracy improved from 0.98641 to 0.98666, saving model to bilstm_cnn_crf/cp.ckpt\n",
            "270/270 [==============================] - 441s 2s/step - decode_sequence_accuracy: 0.9909 - loss: 1.4466 - val_decode_sequence_accuracy: 0.9867 - val_loss: 2.5015\n",
            "Epoch 9/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9912 - loss: 1.3435\n",
            "Epoch 9: val_decode_sequence_accuracy improved from 0.98666 to 0.98683, saving model to bilstm_cnn_crf/cp.ckpt\n",
            "270/270 [==============================] - 440s 2s/step - decode_sequence_accuracy: 0.9912 - loss: 1.3436 - val_decode_sequence_accuracy: 0.9868 - val_loss: 2.4949\n",
            "Epoch 10/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9916 - loss: 1.2503\n",
            "Epoch 10: val_decode_sequence_accuracy did not improve from 0.98683\n",
            "270/270 [==============================] - 436s 2s/step - decode_sequence_accuracy: 0.9916 - loss: 1.2502 - val_decode_sequence_accuracy: 0.9866 - val_loss: 2.5095\n",
            "Epoch 11/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9918 - loss: 1.1611\n",
            "Epoch 11: val_decode_sequence_accuracy did not improve from 0.98683\n",
            "270/270 [==============================] - 431s 2s/step - decode_sequence_accuracy: 0.9918 - loss: 1.1603 - val_decode_sequence_accuracy: 0.9861 - val_loss: 2.5245\n",
            "Epoch 12/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9920 - loss: 1.0961\n",
            "Epoch 12: val_decode_sequence_accuracy did not improve from 0.98683\n",
            "270/270 [==============================] - 431s 2s/step - decode_sequence_accuracy: 0.9920 - loss: 1.0981 - val_decode_sequence_accuracy: 0.9862 - val_loss: 2.7140\n",
            "Epoch 13/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9922 - loss: 1.0351\n",
            "Epoch 13: val_decode_sequence_accuracy did not improve from 0.98683\n",
            "270/270 [==============================] - 432s 2s/step - decode_sequence_accuracy: 0.9922 - loss: 1.0355 - val_decode_sequence_accuracy: 0.9860 - val_loss: 2.7445\n",
            "Epoch 13: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('bilstm_cnn_crf/cp.ckpt')\n",
        "\n",
        "i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
        "# 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
        "y_predicted = model.predict([np.array([X_test[i]]), np.array([X_char_test[i]])])[0] \n",
        "labels = np.argmax(y_test[i], -1) # 원-핫 벡터를 정수 인코딩으로 변경.\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for word, tag, pred in zip(X_test[i], labels, y_predicted[0]):\n",
        "    if word != 0: # PAD값은 제외함.\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku2t-wpxTKLE",
        "outputId": "70ca286e-d557-4685-9d2a-1dfe8e011602"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "the              : O       O\n",
            "statement        : O       O\n",
            "came             : O       O\n",
            "as               : O       O\n",
            "u.n.             : B-org   B-org\n",
            "secretary-general: I-org   I-org\n",
            "kofi             : B-per   B-per\n",
            "annan            : I-per   I-per\n",
            "met              : O       O\n",
            "with             : O       O\n",
            "officials        : O       O\n",
            "in               : O       O\n",
            "amman            : B-geo   B-geo\n",
            "to               : O       O\n",
            "discuss          : O       O\n",
            "wednesday        : B-tim   B-tim\n",
            "'s               : O       O\n",
            "attacks          : O       O\n",
            ".                : O       O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict([X_test, X_char_test])[0]\n",
        "pred_tags = sequences_to_tag_for_crf(y_predicted)\n",
        "test_tags = sequences_to_tag(y_test)\n",
        "\n",
        "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n",
        "print(classification_report(test_tags, pred_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_X-agYVTMN4",
        "outputId": "30a77e7d-bd25-484f-f837-61755fca693b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 81.0%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        63\n",
            "         eve       0.67      0.27      0.38        52\n",
            "         geo       0.84      0.86      0.85      7620\n",
            "         gpe       0.95      0.94      0.95      3145\n",
            "         nat       0.69      0.24      0.36        37\n",
            "         org       0.68      0.60      0.64      4033\n",
            "         per       0.79      0.71      0.75      3545\n",
            "         tim       0.88      0.85      0.87      4067\n",
            "\n",
            "   micro avg       0.83      0.79      0.81     22562\n",
            "   macro avg       0.69      0.56      0.60     22562\n",
            "weighted avg       0.82      0.79      0.81     22562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BiLSTM-BiLSTM-CRF"
      ],
      "metadata": {
        "id": "k70eVbEpTQsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "char_embedding_dim = 64\n",
        "dropout_ratio = 0.3\n",
        "hidden_units = 64\n",
        "\n",
        "# 단어 임베딩\n",
        "word_ids = Input(batch_shape=(None, None), dtype='int32', name='word_input')\n",
        "word_embeddings = Embedding(input_dim=vocab_size,\n",
        "                                        output_dim=embedding_dim,\n",
        "                                        name='word_embedding')(word_ids)\n",
        "\n",
        "# char 임베딩\n",
        "char_ids = Input(batch_shape=(None, None, None), dtype='int32', name='char_input')\n",
        "char_embeddings = Embedding(input_dim=(len(char_to_index)),\n",
        "                                        output_dim=char_embedding_dim,\n",
        "                                        embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5),\n",
        "                                        name='char_embedding')(char_ids)\n",
        "\n",
        "# char 임베딩을 BiLSTM을 통과 시켜 단어 벡터를 얻고 단어 임베딩과 연결\n",
        "char_embeddings = TimeDistributed(Bidirectional(LSTM(hidden_units)))(char_embeddings)\n",
        "output = concatenate([word_embeddings, char_embeddings])\n",
        "\n",
        "# 연결한 벡터를 가지고 문장의 길이만큼 LSTM을 수행\n",
        "output = Dropout(dropout_ratio)(output)\n",
        "output = Bidirectional(LSTM(units=hidden_units, return_sequences=True))(output)\n",
        "\n",
        "# 출력층\n",
        "output = TimeDistributed(Dense(tag_size, activation='relu'))(output)\n",
        "\n",
        "base = Model(inputs=[word_ids, char_ids], outputs=[output])\n",
        "model = CRFModel(base, tag_size)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), metrics='accuracy')\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('bilstm_bilstm_crf/cp.ckpt', monitor='val_decode_sequence_accuracy', mode='max', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "history = model.fit([X_train, X_char_train], y_train_int, batch_size=128, epochs=15, validation_split=0.1, callbacks=[mc, es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juoSgf-sTN1W",
        "outputId": "478131dd-257e-40a9-eb9d-799bb149c6bb"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9229 - loss: 22.7061\n",
            "Epoch 1: val_decode_sequence_accuracy improved from -inf to 0.97379, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 614s 2s/step - decode_sequence_accuracy: 0.9229 - loss: 22.6452 - val_decode_sequence_accuracy: 0.9738 - val_loss: 6.6901\n",
            "Epoch 2/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9810 - loss: 4.4274\n",
            "Epoch 2: val_decode_sequence_accuracy improved from 0.97379 to 0.98424, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 611s 2s/step - decode_sequence_accuracy: 0.9810 - loss: 4.4265 - val_decode_sequence_accuracy: 0.9842 - val_loss: 3.4949\n",
            "Epoch 3/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9864 - loss: 2.8372\n",
            "Epoch 3: val_decode_sequence_accuracy improved from 0.98424 to 0.98581, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 605s 2s/step - decode_sequence_accuracy: 0.9864 - loss: 2.8342 - val_decode_sequence_accuracy: 0.9858 - val_loss: 2.8034\n",
            "Epoch 4/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9885 - loss: 2.2294\n",
            "Epoch 4: val_decode_sequence_accuracy improved from 0.98581 to 0.98640, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 631s 2s/step - decode_sequence_accuracy: 0.9885 - loss: 2.2282 - val_decode_sequence_accuracy: 0.9864 - val_loss: 2.6997\n",
            "Epoch 5/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9897 - loss: 1.8913\n",
            "Epoch 5: val_decode_sequence_accuracy improved from 0.98640 to 0.98671, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 664s 2s/step - decode_sequence_accuracy: 0.9897 - loss: 1.8921 - val_decode_sequence_accuracy: 0.9867 - val_loss: 2.5693\n",
            "Epoch 6/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9905 - loss: 1.6546\n",
            "Epoch 6: val_decode_sequence_accuracy did not improve from 0.98671\n",
            "270/270 [==============================] - 654s 2s/step - decode_sequence_accuracy: 0.9905 - loss: 1.6542 - val_decode_sequence_accuracy: 0.9866 - val_loss: 2.5846\n",
            "Epoch 7/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9912 - loss: 1.4789\n",
            "Epoch 7: val_decode_sequence_accuracy did not improve from 0.98671\n",
            "270/270 [==============================] - 655s 2s/step - decode_sequence_accuracy: 0.9912 - loss: 1.4796 - val_decode_sequence_accuracy: 0.9864 - val_loss: 2.5597\n",
            "Epoch 8/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9916 - loss: 1.3445\n",
            "Epoch 8: val_decode_sequence_accuracy improved from 0.98671 to 0.98676, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 625s 2s/step - decode_sequence_accuracy: 0.9916 - loss: 1.3460 - val_decode_sequence_accuracy: 0.9868 - val_loss: 2.5394\n",
            "Epoch 9/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9921 - loss: 1.2215\n",
            "Epoch 9: val_decode_sequence_accuracy did not improve from 0.98676\n",
            "270/270 [==============================] - 621s 2s/step - decode_sequence_accuracy: 0.9921 - loss: 1.2209 - val_decode_sequence_accuracy: 0.9860 - val_loss: 2.7369\n",
            "Epoch 10/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9925 - loss: 1.1233\n",
            "Epoch 10: val_decode_sequence_accuracy did not improve from 0.98676\n",
            "270/270 [==============================] - 609s 2s/step - decode_sequence_accuracy: 0.9925 - loss: 1.1251 - val_decode_sequence_accuracy: 0.9855 - val_loss: 2.8079\n",
            "Epoch 11/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9929 - loss: 1.0212\n",
            "Epoch 11: val_decode_sequence_accuracy did not improve from 0.98676\n",
            "270/270 [==============================] - 616s 2s/step - decode_sequence_accuracy: 0.9929 - loss: 1.0217 - val_decode_sequence_accuracy: 0.9861 - val_loss: 2.7497\n",
            "Epoch 12/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9932 - loss: 0.9455\n",
            "Epoch 12: val_decode_sequence_accuracy did not improve from 0.98676\n",
            "270/270 [==============================] - 611s 2s/step - decode_sequence_accuracy: 0.9932 - loss: 0.9455 - val_decode_sequence_accuracy: 0.9860 - val_loss: 2.8741\n",
            "Epoch 12: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('bilstm_bilstm_crf/cp.ckpt')\n",
        "\n",
        "i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
        "# 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
        "y_predicted = model.predict([np.array([X_test[i]]), np.array([X_char_test[i]])])[0]\n",
        "labels = np.argmax(y_test[i], -1) # 원-핫 벡터를 정수 인코딩으로 변경.\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for word, tag, pred in zip(X_test[i], labels, y_predicted[0]):\n",
        "    if word != 0: # PAD값은 제외함.\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n2xqgcUTW7e",
        "outputId": "bea392fc-e841-4ca5-e789-e4119d4ecc8f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "the              : O       O\n",
            "statement        : O       O\n",
            "came             : O       O\n",
            "as               : O       O\n",
            "u.n.             : B-org   B-org\n",
            "secretary-general: I-org   I-org\n",
            "kofi             : B-per   B-per\n",
            "annan            : I-per   I-per\n",
            "met              : O       O\n",
            "with             : O       O\n",
            "officials        : O       O\n",
            "in               : O       O\n",
            "amman            : B-geo   B-geo\n",
            "to               : O       O\n",
            "discuss          : O       O\n",
            "wednesday        : B-tim   B-tim\n",
            "'s               : O       O\n",
            "attacks          : O       O\n",
            ".                : O       O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict([X_test, X_char_test])[0]\n",
        "pred_tags = sequences_to_tag_for_crf(y_predicted)\n",
        "test_tags = sequences_to_tag(y_test)\n",
        "\n",
        "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n",
        "print(classification_report(test_tags, pred_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhRcrbDgTYCT",
        "outputId": "4e23ea0c-8dbd-4bb4-f787-3a04842c6959"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 80.9%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.33      0.02      0.03        63\n",
            "         eve       0.72      0.25      0.37        52\n",
            "         geo       0.83      0.87      0.85      7620\n",
            "         gpe       0.95      0.94      0.95      3145\n",
            "         nat       0.00      0.00      0.00        37\n",
            "         org       0.66      0.58      0.62      4033\n",
            "         per       0.79      0.73      0.76      3545\n",
            "         tim       0.87      0.85      0.86      4067\n",
            "\n",
            "   micro avg       0.82      0.80      0.81     22562\n",
            "   macro avg       0.65      0.53      0.55     22562\n",
            "weighted avg       0.81      0.80      0.80     22562\n",
            "\n"
          ]
        }
      ]
    }
  ]
}