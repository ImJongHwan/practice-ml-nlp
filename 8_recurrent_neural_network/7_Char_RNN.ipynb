{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7_Char_RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPUUOC8z8GdXq3nDA9VezmP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImJongHwan/practice-ml-nlp/blob/main/8_recurrent_neural_network/7_Char_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문자 단위 RNN(Char RNN)\n",
        "\n",
        "https://wikidocs.net/48649"
      ],
      "metadata": {
        "id": "nEONL0T2lqh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문자 단위 RNN 언어 모델 (Char RNNLM)"
      ],
      "metadata": {
        "id": "odTPKNZ-lv90"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Pk2_IBqAllj4"
      },
      "outputs": [],
      "source": [
        "## 데이터에 대한 이해와 전처리\n",
        "\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")\n",
        "\n",
        "f = open('11-0.txt', 'rb')\n",
        "sentences = []\n",
        "for sentence in f:\n",
        "  sentence = sentence.strip()\n",
        "  sentence = sentence.lower()\n",
        "  sentence = sentence.decode('ascii', 'ignore')\n",
        "  if len(sentence) > 0:\n",
        "    sentences.append(sentence)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPf_yMaQmYcx",
        "outputId": "46ce5cf3-92a1-4142-f476-703fe667ff7e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll',\n",
              " 'this ebook is for the use of anyone anywhere in the united states and',\n",
              " 'most other parts of the world at no cost and with almost no restrictions',\n",
              " 'whatsoever. you may copy it, give it away or re-use it under the terms',\n",
              " 'of the project gutenberg license included with this ebook or online at']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_data = ' '.join(sentences)\n",
        "print('문자열의 길이 또는 총 문자의 개수: %d' % len(total_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT6z6eFlmabI",
        "outputId": "e5eea44b-85bb-42c1-fa82-69a53b36c841"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자열의 길이 또는 총 문자의 개수: 159484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_data[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s5pefASncvM",
        "outputId": "446087a9-e352-4210-d2e4-1276d0dc3b12"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the project gutenberg ebook of alices adventures in wonderland, by lewis carroll this ebook is for the use of anyone anywhere in the united states and most other parts of the world at no cost and with\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_vocab = sorted(list(set(total_data)))\n",
        "vocab_size = len(char_vocab)\n",
        "print(f'문자 집합의 크기: {vocab_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C07gyGuFneSr",
        "outputId": "30131796-7228-4010-f091-484308099854"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합의 크기: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index = dict((char, index) for index, char in enumerate(char_vocab))\n",
        "print('문자 집합', char_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ggCMt8tnpha",
        "outputId": "f8fa7835-f166-4eec-ffa7-d84fe7e4f789"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합 {' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '[': 27, ']': 28, '_': 29, 'a': 30, 'b': 31, 'c': 32, 'd': 33, 'e': 34, 'f': 35, 'g': 36, 'h': 37, 'i': 38, 'j': 39, 'k': 40, 'l': 41, 'm': 42, 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_char = {}\n",
        "for key, value in char_to_index.items():\n",
        "  index_to_char[value] = key"
      ],
      "metadata": {
        "id": "z4lUqm9Qn1on"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = 'appl'\n",
        "train_y = 'pple'"
      ],
      "metadata": {
        "id": "ObFWmcmXogrH"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 60\n",
        "\n",
        "n_samples = int(np.floor((len(total_data) - 1) / seq_length))\n",
        "print(f'샘플의 수: {n_samples}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGnhqR6Fo5H0",
        "outputId": "9fcd7147-a50d-48a6-b519-3de213493435"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 수: 2658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = []\n",
        "train_y = []\n",
        "\n",
        "for i in range(n_samples):\n",
        "  X_sample = total_data[i * seq_length: (i+1) * seq_length]\n",
        "\n",
        "  X_encoded = [char_to_index[c] for c in X_sample]\n",
        "  train_X.append(X_encoded)\n",
        "\n",
        "  y_sample = total_data[i * seq_length + 1: (i + 1) * seq_length +1]\n",
        "  y_encoded = [char_to_index[c] for c in y_sample]\n",
        "  train_y.append(y_encoded)"
      ],
      "metadata": {
        "id": "W6TYCdbBpznm"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('X 데이터의 첫번째 샘플: ', train_X[0])\n",
        "print('y 데이터의 첫번째 샘플: ', train_y[0])\n",
        "print('-'*50)\n",
        "print('X 데이터의 첫번째 샘플 디코딩: ', [index_to_char[i] for i in train_X[0]])\n",
        "print('y 데이터의 첫번째 샘플 디코딩: ', [index_to_char[i] for i in train_y[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wArB3DUKqSZc",
        "outputId": "dcd805a8-6234-4367-c9d6-e0c24f519d29"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X 데이터의 첫번째 샘플:  [49, 37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30]\n",
            "y 데이터의 첫번째 샘플:  [37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30, 43]\n",
            "--------------------------------------------------\n",
            "X 데이터의 첫번째 샘플 디코딩:  ['t', 'h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'o', 'f', ' ', 'a', 'l', 'i', 'c', 'e', 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ', 'i', 'n', ' ', 'w', 'o', 'n', 'd', 'e', 'r', 'l', 'a']\n",
            "y 데이터의 첫번째 샘플 디코딩:  ['h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'o', 'f', ' ', 'a', 'l', 'i', 'c', 'e', 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ', 'i', 'n', ' ', 'w', 'o', 'n', 'd', 'e', 'r', 'l', 'a', 'n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_X[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaJAvTs3qzQI",
        "outputId": "d91a09eb-d250-4c18-d796-9cffaa1c1484"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[43, 33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_y[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mnX1kBhuCdu",
        "outputId": "40ab4ffd-99db-4fb3-907d-b257f4960c70"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54, 52]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = to_categorical(train_X)\n",
        "train_y = to_categorical(train_y)\n",
        "\n",
        "print(f'train_X의 크기(shape): {train_X.shape}')\n",
        "print(f'train_y의 크기(shape): {train_y.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaoqWsPNuEYd",
        "outputId": "a1cfef9c-0125-4edc-c2ed-4624a4a1ee9d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_X의 크기(shape): (2658, 60, 56)\n",
            "train_y의 크기(shape): (2658, 60, 56)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델 설계하기\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed"
      ],
      "metadata": {
        "id": "c2YqrxsFuUIE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_units = 256\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_units, input_shape=(None, train_X.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(hidden_units, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(train_X, train_y, epochs=80, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEAZV5jBwceY",
        "outputId": "978a69ad-41ff-4d44-bb8d-2d0dc15a6885"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "84/84 - 48s - loss: 3.0706 - accuracy: 0.1826 - 48s/epoch - 569ms/step\n",
            "Epoch 2/80\n",
            "84/84 - 37s - loss: 2.7126 - accuracy: 0.2519 - 37s/epoch - 445ms/step\n",
            "Epoch 3/80\n",
            "84/84 - 37s - loss: 2.3790 - accuracy: 0.3320 - 37s/epoch - 441ms/step\n",
            "Epoch 4/80\n",
            "84/84 - 38s - loss: 2.2445 - accuracy: 0.3631 - 38s/epoch - 450ms/step\n",
            "Epoch 5/80\n",
            "84/84 - 37s - loss: 2.1353 - accuracy: 0.3890 - 37s/epoch - 442ms/step\n",
            "Epoch 6/80\n",
            "84/84 - 37s - loss: 2.0547 - accuracy: 0.4081 - 37s/epoch - 442ms/step\n",
            "Epoch 7/80\n",
            "84/84 - 43s - loss: 1.9789 - accuracy: 0.4299 - 43s/epoch - 509ms/step\n",
            "Epoch 8/80\n",
            "84/84 - 38s - loss: 1.9183 - accuracy: 0.4448 - 38s/epoch - 449ms/step\n",
            "Epoch 9/80\n",
            "84/84 - 37s - loss: 1.8623 - accuracy: 0.4601 - 37s/epoch - 442ms/step\n",
            "Epoch 10/80\n",
            "84/84 - 37s - loss: 1.8138 - accuracy: 0.4743 - 37s/epoch - 438ms/step\n",
            "Epoch 11/80\n",
            "84/84 - 37s - loss: 1.7675 - accuracy: 0.4878 - 37s/epoch - 435ms/step\n",
            "Epoch 12/80\n",
            "84/84 - 37s - loss: 1.7222 - accuracy: 0.4986 - 37s/epoch - 436ms/step\n",
            "Epoch 13/80\n",
            "84/84 - 37s - loss: 1.6823 - accuracy: 0.5103 - 37s/epoch - 435ms/step\n",
            "Epoch 14/80\n",
            "84/84 - 37s - loss: 1.6443 - accuracy: 0.5208 - 37s/epoch - 439ms/step\n",
            "Epoch 15/80\n",
            "84/84 - 37s - loss: 1.6069 - accuracy: 0.5300 - 37s/epoch - 437ms/step\n",
            "Epoch 16/80\n",
            "84/84 - 37s - loss: 1.5747 - accuracy: 0.5372 - 37s/epoch - 436ms/step\n",
            "Epoch 17/80\n",
            "84/84 - 37s - loss: 1.5393 - accuracy: 0.5473 - 37s/epoch - 440ms/step\n",
            "Epoch 18/80\n",
            "84/84 - 37s - loss: 1.5078 - accuracy: 0.5554 - 37s/epoch - 444ms/step\n",
            "Epoch 19/80\n",
            "84/84 - 38s - loss: 1.4782 - accuracy: 0.5628 - 38s/epoch - 448ms/step\n",
            "Epoch 20/80\n",
            "84/84 - 37s - loss: 1.4468 - accuracy: 0.5729 - 37s/epoch - 439ms/step\n",
            "Epoch 21/80\n",
            "84/84 - 36s - loss: 1.4204 - accuracy: 0.5778 - 36s/epoch - 433ms/step\n",
            "Epoch 22/80\n",
            "84/84 - 36s - loss: 1.3883 - accuracy: 0.5879 - 36s/epoch - 434ms/step\n",
            "Epoch 23/80\n",
            "84/84 - 41s - loss: 1.3599 - accuracy: 0.5954 - 41s/epoch - 483ms/step\n",
            "Epoch 24/80\n",
            "84/84 - 37s - loss: 1.3356 - accuracy: 0.6028 - 37s/epoch - 441ms/step\n",
            "Epoch 25/80\n",
            "84/84 - 37s - loss: 1.3070 - accuracy: 0.6096 - 37s/epoch - 439ms/step\n",
            "Epoch 26/80\n",
            "84/84 - 37s - loss: 1.2808 - accuracy: 0.6172 - 37s/epoch - 442ms/step\n",
            "Epoch 27/80\n",
            "84/84 - 36s - loss: 1.2506 - accuracy: 0.6261 - 36s/epoch - 434ms/step\n",
            "Epoch 28/80\n",
            "84/84 - 37s - loss: 1.2233 - accuracy: 0.6343 - 37s/epoch - 436ms/step\n",
            "Epoch 29/80\n",
            "84/84 - 41s - loss: 1.2012 - accuracy: 0.6407 - 41s/epoch - 493ms/step\n",
            "Epoch 30/80\n",
            "84/84 - 47s - loss: 1.1735 - accuracy: 0.6491 - 47s/epoch - 556ms/step\n",
            "Epoch 31/80\n",
            "84/84 - 39s - loss: 1.1419 - accuracy: 0.6578 - 39s/epoch - 461ms/step\n",
            "Epoch 32/80\n",
            "84/84 - 37s - loss: 1.1151 - accuracy: 0.6667 - 37s/epoch - 443ms/step\n",
            "Epoch 33/80\n",
            "84/84 - 37s - loss: 1.0893 - accuracy: 0.6735 - 37s/epoch - 445ms/step\n",
            "Epoch 34/80\n",
            "84/84 - 38s - loss: 1.0608 - accuracy: 0.6823 - 38s/epoch - 449ms/step\n",
            "Epoch 35/80\n",
            "84/84 - 37s - loss: 1.0330 - accuracy: 0.6918 - 37s/epoch - 440ms/step\n",
            "Epoch 36/80\n",
            "84/84 - 37s - loss: 1.0068 - accuracy: 0.6986 - 37s/epoch - 442ms/step\n",
            "Epoch 37/80\n",
            "84/84 - 37s - loss: 0.9797 - accuracy: 0.7082 - 37s/epoch - 441ms/step\n",
            "Epoch 38/80\n",
            "84/84 - 37s - loss: 0.9486 - accuracy: 0.7185 - 37s/epoch - 446ms/step\n",
            "Epoch 39/80\n",
            "84/84 - 37s - loss: 0.9241 - accuracy: 0.7252 - 37s/epoch - 439ms/step\n",
            "Epoch 40/80\n",
            "84/84 - 44s - loss: 0.8957 - accuracy: 0.7337 - 44s/epoch - 521ms/step\n",
            "Epoch 41/80\n",
            "84/84 - 44s - loss: 0.8681 - accuracy: 0.7425 - 44s/epoch - 520ms/step\n",
            "Epoch 42/80\n",
            "84/84 - 43s - loss: 0.8494 - accuracy: 0.7472 - 43s/epoch - 506ms/step\n",
            "Epoch 43/80\n",
            "84/84 - 46s - loss: 0.8188 - accuracy: 0.7579 - 46s/epoch - 544ms/step\n",
            "Epoch 44/80\n",
            "84/84 - 42s - loss: 0.7946 - accuracy: 0.7654 - 42s/epoch - 503ms/step\n",
            "Epoch 45/80\n",
            "84/84 - 37s - loss: 0.7650 - accuracy: 0.7755 - 37s/epoch - 437ms/step\n",
            "Epoch 46/80\n",
            "84/84 - 38s - loss: 0.7438 - accuracy: 0.7803 - 38s/epoch - 448ms/step\n",
            "Epoch 47/80\n",
            "84/84 - 37s - loss: 0.7218 - accuracy: 0.7877 - 37s/epoch - 437ms/step\n",
            "Epoch 48/80\n",
            "84/84 - 37s - loss: 0.6992 - accuracy: 0.7948 - 37s/epoch - 441ms/step\n",
            "Epoch 49/80\n",
            "84/84 - 37s - loss: 0.6692 - accuracy: 0.8057 - 37s/epoch - 438ms/step\n",
            "Epoch 50/80\n",
            "84/84 - 37s - loss: 0.6467 - accuracy: 0.8127 - 37s/epoch - 440ms/step\n",
            "Epoch 51/80\n",
            "84/84 - 37s - loss: 0.6257 - accuracy: 0.8194 - 37s/epoch - 435ms/step\n",
            "Epoch 52/80\n",
            "84/84 - 36s - loss: 0.6140 - accuracy: 0.8213 - 36s/epoch - 434ms/step\n",
            "Epoch 53/80\n",
            "84/84 - 37s - loss: 0.5830 - accuracy: 0.8325 - 37s/epoch - 435ms/step\n",
            "Epoch 54/80\n",
            "84/84 - 36s - loss: 0.5640 - accuracy: 0.8382 - 36s/epoch - 430ms/step\n",
            "Epoch 55/80\n",
            "84/84 - 37s - loss: 0.5446 - accuracy: 0.8443 - 37s/epoch - 439ms/step\n",
            "Epoch 56/80\n",
            "84/84 - 37s - loss: 0.5197 - accuracy: 0.8526 - 37s/epoch - 435ms/step\n",
            "Epoch 57/80\n",
            "84/84 - 36s - loss: 0.4984 - accuracy: 0.8595 - 36s/epoch - 432ms/step\n",
            "Epoch 58/80\n",
            "84/84 - 37s - loss: 0.4852 - accuracy: 0.8640 - 37s/epoch - 445ms/step\n",
            "Epoch 59/80\n",
            "84/84 - 37s - loss: 0.4811 - accuracy: 0.8635 - 37s/epoch - 438ms/step\n",
            "Epoch 60/80\n",
            "84/84 - 36s - loss: 0.4523 - accuracy: 0.8748 - 36s/epoch - 433ms/step\n",
            "Epoch 61/80\n",
            "84/84 - 37s - loss: 0.4254 - accuracy: 0.8845 - 37s/epoch - 441ms/step\n",
            "Epoch 62/80\n",
            "84/84 - 37s - loss: 0.4125 - accuracy: 0.8875 - 37s/epoch - 442ms/step\n",
            "Epoch 63/80\n",
            "84/84 - 37s - loss: 0.4240 - accuracy: 0.8814 - 37s/epoch - 440ms/step\n",
            "Epoch 64/80\n",
            "84/84 - 37s - loss: 0.3975 - accuracy: 0.8917 - 37s/epoch - 435ms/step\n",
            "Epoch 65/80\n",
            "84/84 - 37s - loss: 0.4331 - accuracy: 0.8738 - 37s/epoch - 440ms/step\n",
            "Epoch 66/80\n",
            "84/84 - 37s - loss: 0.3659 - accuracy: 0.9024 - 37s/epoch - 440ms/step\n",
            "Epoch 67/80\n",
            "84/84 - 37s - loss: 0.3667 - accuracy: 0.9003 - 37s/epoch - 435ms/step\n",
            "Epoch 68/80\n",
            "84/84 - 37s - loss: 0.3242 - accuracy: 0.9171 - 37s/epoch - 440ms/step\n",
            "Epoch 69/80\n",
            "84/84 - 37s - loss: 0.2989 - accuracy: 0.9267 - 37s/epoch - 441ms/step\n",
            "Epoch 70/80\n",
            "84/84 - 37s - loss: 0.2966 - accuracy: 0.9254 - 37s/epoch - 446ms/step\n",
            "Epoch 71/80\n",
            "84/84 - 37s - loss: 0.2822 - accuracy: 0.9308 - 37s/epoch - 443ms/step\n",
            "Epoch 72/80\n",
            "84/84 - 37s - loss: 0.2741 - accuracy: 0.9330 - 37s/epoch - 441ms/step\n",
            "Epoch 73/80\n",
            "84/84 - 38s - loss: 0.2734 - accuracy: 0.9318 - 38s/epoch - 446ms/step\n",
            "Epoch 74/80\n",
            "84/84 - 41s - loss: 0.2544 - accuracy: 0.9381 - 41s/epoch - 485ms/step\n",
            "Epoch 75/80\n",
            "84/84 - 47s - loss: 0.2486 - accuracy: 0.9394 - 47s/epoch - 560ms/step\n",
            "Epoch 76/80\n",
            "84/84 - 42s - loss: 0.2323 - accuracy: 0.9448 - 42s/epoch - 495ms/step\n",
            "Epoch 77/80\n",
            "84/84 - 44s - loss: 0.2290 - accuracy: 0.9449 - 44s/epoch - 529ms/step\n",
            "Epoch 78/80\n",
            "84/84 - 45s - loss: 0.2254 - accuracy: 0.9457 - 45s/epoch - 539ms/step\n",
            "Epoch 79/80\n",
            "84/84 - 43s - loss: 0.2199 - accuracy: 0.9464 - 43s/epoch - 512ms/step\n",
            "Epoch 80/80\n",
            "84/84 - 40s - loss: 0.2048 - accuracy: 0.9516 - 40s/epoch - 480ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe728483450>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(model, length):\n",
        "  ix = [np.random.randint(vocab_size)]\n",
        "\n",
        "  y_char = [index_to_char[ix[-1]]]\n",
        "  print(ix[-1], '번 문자', y_char[-1],'로 예측을 시작!')\n",
        "\n",
        "  X = np.zeros((1, length, vocab_size))\n",
        "\n",
        "  for i in range(length):\n",
        "    X[0][i][ix[-1]] = 1\n",
        "    print(index_to_char[ix[-1]], end=\"\")\n",
        "    ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
        "    y_char.append(index_to_char[ix[-1]])\n",
        "  return ('').join(y_char)"
      ],
      "metadata": {
        "id": "lY_gmvUAw5xG"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = sentence_generation(model, 100)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI4UsTKsx-X9",
        "outputId": "2a553527-d96c-4136-91ef-7d43631202ed"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35 번 문자 f 로 예측을 시작!\n",
            "f the month, and doesnt tell what oclock it is! why should it had leet of the side, the queen was hif the month, and doesnt tell what oclock it is! why should it had leet of the side, the queen was his\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문자 단위 RNN(Char RNN)으로 텍스트 생성하기"
      ],
      "metadata": {
        "id": "DFpXJred8mCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터에 대한 이해와 전처리\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "rK_ZKY5O2wNi"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = '''\n",
        "I get on with life as a programmer,\n",
        "I like to contemplate beer.\n",
        "But when I start to daydream,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "Do I love wine more than beer?\n",
        "\n",
        "I like to use words about beer.\n",
        "But when I stop my talking,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "I hate bugs and errors.\n",
        "But I just think back to wine,\n",
        "And I'm happy once again.\n",
        "\n",
        "I like to hang out with programming and deep learning.\n",
        "But when left alone,\n",
        "My mind turns straight to wine.\n",
        "'''"
      ],
      "metadata": {
        "id": "UI9qpr7e22g2"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = raw_text.split()\n",
        "raw_text = ' '.join(tokens)\n",
        "print(raw_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6T-lcKO296I",
        "outputId": "7cece8e3-a894-496e-85c6-cd33e795dfab"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I get on with life as a programmer, I like to contemplate beer. But when I start to daydream, My mind turns straight to wine. Do I love wine more than beer? I like to use words about beer. But when I stop my talking, My mind turns straight to wine. I hate bugs and errors. But I just think back to wine, And I'm happy once again. I like to hang out with programming and deep learning. But when left alone, My mind turns straight to wine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_vocab = sorted(list(set(raw_text)))\n",
        "vocab_size = len(char_vocab)\n",
        "print('문자 집합: ', char_vocab)\n",
        "print(f'문자 집합의 크기: {vocab_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R6Nbn_w3EKI",
        "outputId": "bb517b30-7a31-4b47-c0be-147b7ffb829e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합:  [' ', \"'\", ',', '.', '?', 'A', 'B', 'D', 'I', 'M', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n",
            "문자 집합의 크기: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index = dict((char, index) for index, char in enumerate(char_vocab))\n",
        "print(char_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjVbL8T-3TNn",
        "outputId": "2d355f7e-c65f-4cc0-cff9-b2143b42e7db"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, \"'\": 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'D': 7, 'I': 8, 'M': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'r': 26, 's': 27, 't': 28, 'u': 29, 'v': 30, 'w': 31, 'y': 32}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length = 11\n",
        "sequences = []\n",
        "for i in range(length, len(raw_text)):\n",
        "  seq = raw_text[i-length:i]\n",
        "  sequences.append(seq)\n",
        "print('총 훈련 샘플의 수: %d' % len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mICylohB3ZiF",
        "outputId": "b56ed89b-c051-4f92-af3c-306d7355465d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 훈련 샘플의 수: 426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l018D0C870j7",
        "outputId": "83154969-8248-47b9-9668-44e61701b73b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I get on wi',\n",
              " ' get on wit',\n",
              " 'get on with',\n",
              " 'et on with ',\n",
              " 't on with l',\n",
              " ' on with li',\n",
              " 'on with lif',\n",
              " 'n with life',\n",
              " ' with life ',\n",
              " 'with life a']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sequences = []\n",
        "for sequence in sequences:\n",
        "  encoded_sequence = [char_to_index[char] for char in sequence]\n",
        "  encoded_sequences.append(encoded_sequence)"
      ],
      "metadata": {
        "id": "6VJgy8-b72Ni"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sequences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psqRKPiV8DHL",
        "outputId": "b53c90eb-1bce-4c91-9173-c12cda5a78cd"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 0, 16, 14, 28, 0, 24, 23, 0, 31, 18],\n",
              " [0, 16, 14, 28, 0, 24, 23, 0, 31, 18, 28],\n",
              " [16, 14, 28, 0, 24, 23, 0, 31, 18, 28, 17],\n",
              " [14, 28, 0, 24, 23, 0, 31, 18, 28, 17, 0],\n",
              " [28, 0, 24, 23, 0, 31, 18, 28, 17, 0, 21]]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sequences = np.array(encoded_sequences)\n",
        "\n",
        "X_data = encoded_sequences[:, :-1]\n",
        "y_data = encoded_sequences[:, -1]"
      ],
      "metadata": {
        "id": "wZP81mPz8FKJ"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_data[:5])\n",
        "print(y_data[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9th0gRZ8NU4",
        "outputId": "3e7aa8f6-b121-416f-ddc9-87032fa9921b"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8  0 16 14 28  0 24 23  0 31]\n",
            " [ 0 16 14 28  0 24 23  0 31 18]\n",
            " [16 14 28  0 24 23  0 31 18 28]\n",
            " [14 28  0 24 23  0 31 18 28 17]\n",
            " [28  0 24 23  0 31 18 28 17  0]]\n",
            "[18 28 17  0 21]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_data_one_hot = [to_categorical(encoded, num_classes=vocab_size) for encoded in X_data]\n",
        "X_data_one_hot = np.array(X_data_one_hot)\n",
        "y_data_one_hot = to_categorical(y_data, num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "xisxFq308P0w"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_data_one_hot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q5OClLW8czO",
        "outputId": "4fc24743-b299-4545-be9a-cfad32911b96"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(426, 10, 33)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델 설계하기\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "8gTx2uXq8iFm"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_units = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_units, input_shape=(X_data_one_hot.shape[1], X_data_one_hot.shape[2])))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_data_one_hot, y_data_one_hot, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkxZzIpB-RYV",
        "outputId": "fec49000-e41e-41b8-c0b2-85142f3c73a0"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 - 2s - loss: 3.4544 - accuracy: 0.1408 - 2s/epoch - 137ms/step\n",
            "Epoch 2/100\n",
            "14/14 - 0s - loss: 3.3131 - accuracy: 0.1972 - 95ms/epoch - 7ms/step\n",
            "Epoch 3/100\n",
            "14/14 - 0s - loss: 3.0553 - accuracy: 0.1972 - 98ms/epoch - 7ms/step\n",
            "Epoch 4/100\n",
            "14/14 - 0s - loss: 2.9846 - accuracy: 0.1972 - 92ms/epoch - 7ms/step\n",
            "Epoch 5/100\n",
            "14/14 - 0s - loss: 2.9514 - accuracy: 0.1972 - 96ms/epoch - 7ms/step\n",
            "Epoch 6/100\n",
            "14/14 - 0s - loss: 2.9317 - accuracy: 0.1972 - 85ms/epoch - 6ms/step\n",
            "Epoch 7/100\n",
            "14/14 - 0s - loss: 2.9132 - accuracy: 0.1972 - 92ms/epoch - 7ms/step\n",
            "Epoch 8/100\n",
            "14/14 - 0s - loss: 2.8999 - accuracy: 0.1972 - 86ms/epoch - 6ms/step\n",
            "Epoch 9/100\n",
            "14/14 - 0s - loss: 2.8828 - accuracy: 0.1972 - 89ms/epoch - 6ms/step\n",
            "Epoch 10/100\n",
            "14/14 - 0s - loss: 2.8645 - accuracy: 0.1972 - 87ms/epoch - 6ms/step\n",
            "Epoch 11/100\n",
            "14/14 - 0s - loss: 2.8248 - accuracy: 0.1972 - 91ms/epoch - 7ms/step\n",
            "Epoch 12/100\n",
            "14/14 - 0s - loss: 2.8054 - accuracy: 0.2160 - 86ms/epoch - 6ms/step\n",
            "Epoch 13/100\n",
            "14/14 - 0s - loss: 2.7677 - accuracy: 0.2019 - 90ms/epoch - 6ms/step\n",
            "Epoch 14/100\n",
            "14/14 - 0s - loss: 2.7366 - accuracy: 0.2160 - 105ms/epoch - 8ms/step\n",
            "Epoch 15/100\n",
            "14/14 - 0s - loss: 2.6956 - accuracy: 0.2277 - 89ms/epoch - 6ms/step\n",
            "Epoch 16/100\n",
            "14/14 - 0s - loss: 2.6559 - accuracy: 0.2371 - 90ms/epoch - 6ms/step\n",
            "Epoch 17/100\n",
            "14/14 - 0s - loss: 2.6243 - accuracy: 0.2512 - 84ms/epoch - 6ms/step\n",
            "Epoch 18/100\n",
            "14/14 - 0s - loss: 2.5855 - accuracy: 0.2840 - 93ms/epoch - 7ms/step\n",
            "Epoch 19/100\n",
            "14/14 - 0s - loss: 2.5456 - accuracy: 0.2887 - 85ms/epoch - 6ms/step\n",
            "Epoch 20/100\n",
            "14/14 - 0s - loss: 2.5126 - accuracy: 0.2793 - 89ms/epoch - 6ms/step\n",
            "Epoch 21/100\n",
            "14/14 - 0s - loss: 2.4530 - accuracy: 0.3052 - 91ms/epoch - 7ms/step\n",
            "Epoch 22/100\n",
            "14/14 - 0s - loss: 2.4059 - accuracy: 0.3005 - 88ms/epoch - 6ms/step\n",
            "Epoch 23/100\n",
            "14/14 - 0s - loss: 2.3721 - accuracy: 0.3169 - 93ms/epoch - 7ms/step\n",
            "Epoch 24/100\n",
            "14/14 - 0s - loss: 2.3336 - accuracy: 0.3099 - 89ms/epoch - 6ms/step\n",
            "Epoch 25/100\n",
            "14/14 - 0s - loss: 2.2943 - accuracy: 0.3803 - 103ms/epoch - 7ms/step\n",
            "Epoch 26/100\n",
            "14/14 - 0s - loss: 2.2469 - accuracy: 0.3545 - 90ms/epoch - 6ms/step\n",
            "Epoch 27/100\n",
            "14/14 - 0s - loss: 2.2121 - accuracy: 0.3638 - 95ms/epoch - 7ms/step\n",
            "Epoch 28/100\n",
            "14/14 - 0s - loss: 2.1660 - accuracy: 0.3756 - 88ms/epoch - 6ms/step\n",
            "Epoch 29/100\n",
            "14/14 - 0s - loss: 2.1071 - accuracy: 0.4155 - 94ms/epoch - 7ms/step\n",
            "Epoch 30/100\n",
            "14/14 - 0s - loss: 2.0846 - accuracy: 0.4014 - 86ms/epoch - 6ms/step\n",
            "Epoch 31/100\n",
            "14/14 - 0s - loss: 2.0346 - accuracy: 0.4343 - 93ms/epoch - 7ms/step\n",
            "Epoch 32/100\n",
            "14/14 - 0s - loss: 1.9875 - accuracy: 0.4460 - 94ms/epoch - 7ms/step\n",
            "Epoch 33/100\n",
            "14/14 - 0s - loss: 1.9317 - accuracy: 0.4437 - 91ms/epoch - 6ms/step\n",
            "Epoch 34/100\n",
            "14/14 - 0s - loss: 1.9001 - accuracy: 0.4460 - 89ms/epoch - 6ms/step\n",
            "Epoch 35/100\n",
            "14/14 - 0s - loss: 1.8459 - accuracy: 0.4695 - 97ms/epoch - 7ms/step\n",
            "Epoch 36/100\n",
            "14/14 - 0s - loss: 1.8079 - accuracy: 0.4812 - 91ms/epoch - 6ms/step\n",
            "Epoch 37/100\n",
            "14/14 - 0s - loss: 1.7676 - accuracy: 0.4836 - 87ms/epoch - 6ms/step\n",
            "Epoch 38/100\n",
            "14/14 - 0s - loss: 1.7227 - accuracy: 0.5493 - 84ms/epoch - 6ms/step\n",
            "Epoch 39/100\n",
            "14/14 - 0s - loss: 1.6714 - accuracy: 0.5446 - 92ms/epoch - 7ms/step\n",
            "Epoch 40/100\n",
            "14/14 - 0s - loss: 1.6226 - accuracy: 0.5798 - 94ms/epoch - 7ms/step\n",
            "Epoch 41/100\n",
            "14/14 - 0s - loss: 1.5867 - accuracy: 0.5775 - 90ms/epoch - 6ms/step\n",
            "Epoch 42/100\n",
            "14/14 - 0s - loss: 1.5355 - accuracy: 0.6221 - 87ms/epoch - 6ms/step\n",
            "Epoch 43/100\n",
            "14/14 - 0s - loss: 1.5264 - accuracy: 0.5915 - 94ms/epoch - 7ms/step\n",
            "Epoch 44/100\n",
            "14/14 - 0s - loss: 1.4811 - accuracy: 0.6174 - 89ms/epoch - 6ms/step\n",
            "Epoch 45/100\n",
            "14/14 - 0s - loss: 1.4568 - accuracy: 0.6338 - 88ms/epoch - 6ms/step\n",
            "Epoch 46/100\n",
            "14/14 - 0s - loss: 1.4169 - accuracy: 0.6502 - 101ms/epoch - 7ms/step\n",
            "Epoch 47/100\n",
            "14/14 - 0s - loss: 1.3801 - accuracy: 0.6479 - 81ms/epoch - 6ms/step\n",
            "Epoch 48/100\n",
            "14/14 - 0s - loss: 1.3362 - accuracy: 0.6643 - 84ms/epoch - 6ms/step\n",
            "Epoch 49/100\n",
            "14/14 - 0s - loss: 1.3318 - accuracy: 0.6690 - 87ms/epoch - 6ms/step\n",
            "Epoch 50/100\n",
            "14/14 - 0s - loss: 1.2818 - accuracy: 0.6995 - 92ms/epoch - 7ms/step\n",
            "Epoch 51/100\n",
            "14/14 - 0s - loss: 1.2379 - accuracy: 0.6925 - 90ms/epoch - 6ms/step\n",
            "Epoch 52/100\n",
            "14/14 - 0s - loss: 1.1969 - accuracy: 0.6995 - 90ms/epoch - 6ms/step\n",
            "Epoch 53/100\n",
            "14/14 - 0s - loss: 1.1658 - accuracy: 0.7136 - 97ms/epoch - 7ms/step\n",
            "Epoch 54/100\n",
            "14/14 - 0s - loss: 1.1408 - accuracy: 0.7230 - 85ms/epoch - 6ms/step\n",
            "Epoch 55/100\n",
            "14/14 - 0s - loss: 1.0970 - accuracy: 0.7347 - 89ms/epoch - 6ms/step\n",
            "Epoch 56/100\n",
            "14/14 - 0s - loss: 1.0699 - accuracy: 0.7559 - 87ms/epoch - 6ms/step\n",
            "Epoch 57/100\n",
            "14/14 - 0s - loss: 1.0375 - accuracy: 0.7512 - 101ms/epoch - 7ms/step\n",
            "Epoch 58/100\n",
            "14/14 - 0s - loss: 1.0081 - accuracy: 0.7700 - 90ms/epoch - 6ms/step\n",
            "Epoch 59/100\n",
            "14/14 - 0s - loss: 0.9831 - accuracy: 0.7770 - 85ms/epoch - 6ms/step\n",
            "Epoch 60/100\n",
            "14/14 - 0s - loss: 0.9810 - accuracy: 0.7770 - 97ms/epoch - 7ms/step\n",
            "Epoch 61/100\n",
            "14/14 - 0s - loss: 0.9557 - accuracy: 0.7840 - 94ms/epoch - 7ms/step\n",
            "Epoch 62/100\n",
            "14/14 - 0s - loss: 0.9179 - accuracy: 0.7934 - 94ms/epoch - 7ms/step\n",
            "Epoch 63/100\n",
            "14/14 - 0s - loss: 0.8956 - accuracy: 0.8052 - 91ms/epoch - 6ms/step\n",
            "Epoch 64/100\n",
            "14/14 - 0s - loss: 0.8893 - accuracy: 0.8005 - 92ms/epoch - 7ms/step\n",
            "Epoch 65/100\n",
            "14/14 - 0s - loss: 0.8499 - accuracy: 0.8310 - 90ms/epoch - 6ms/step\n",
            "Epoch 66/100\n",
            "14/14 - 0s - loss: 0.8197 - accuracy: 0.8216 - 86ms/epoch - 6ms/step\n",
            "Epoch 67/100\n",
            "14/14 - 0s - loss: 0.8019 - accuracy: 0.8239 - 89ms/epoch - 6ms/step\n",
            "Epoch 68/100\n",
            "14/14 - 0s - loss: 0.7669 - accuracy: 0.8568 - 95ms/epoch - 7ms/step\n",
            "Epoch 69/100\n",
            "14/14 - 0s - loss: 0.7459 - accuracy: 0.8568 - 99ms/epoch - 7ms/step\n",
            "Epoch 70/100\n",
            "14/14 - 0s - loss: 0.7360 - accuracy: 0.8380 - 89ms/epoch - 6ms/step\n",
            "Epoch 71/100\n",
            "14/14 - 0s - loss: 0.7028 - accuracy: 0.8545 - 89ms/epoch - 6ms/step\n",
            "Epoch 72/100\n",
            "14/14 - 0s - loss: 0.6896 - accuracy: 0.8803 - 86ms/epoch - 6ms/step\n",
            "Epoch 73/100\n",
            "14/14 - 0s - loss: 0.6723 - accuracy: 0.8756 - 85ms/epoch - 6ms/step\n",
            "Epoch 74/100\n",
            "14/14 - 0s - loss: 0.6690 - accuracy: 0.8803 - 90ms/epoch - 6ms/step\n",
            "Epoch 75/100\n",
            "14/14 - 0s - loss: 0.6369 - accuracy: 0.8756 - 86ms/epoch - 6ms/step\n",
            "Epoch 76/100\n",
            "14/14 - 0s - loss: 0.6059 - accuracy: 0.8803 - 90ms/epoch - 6ms/step\n",
            "Epoch 77/100\n",
            "14/14 - 0s - loss: 0.5821 - accuracy: 0.9061 - 84ms/epoch - 6ms/step\n",
            "Epoch 78/100\n",
            "14/14 - 0s - loss: 0.5669 - accuracy: 0.9131 - 98ms/epoch - 7ms/step\n",
            "Epoch 79/100\n",
            "14/14 - 0s - loss: 0.5476 - accuracy: 0.9202 - 93ms/epoch - 7ms/step\n",
            "Epoch 80/100\n",
            "14/14 - 0s - loss: 0.5330 - accuracy: 0.9131 - 87ms/epoch - 6ms/step\n",
            "Epoch 81/100\n",
            "14/14 - 0s - loss: 0.5257 - accuracy: 0.9038 - 96ms/epoch - 7ms/step\n",
            "Epoch 82/100\n",
            "14/14 - 0s - loss: 0.4966 - accuracy: 0.9296 - 141ms/epoch - 10ms/step\n",
            "Epoch 83/100\n",
            "14/14 - 0s - loss: 0.4862 - accuracy: 0.9366 - 126ms/epoch - 9ms/step\n",
            "Epoch 84/100\n",
            "14/14 - 0s - loss: 0.4839 - accuracy: 0.9390 - 94ms/epoch - 7ms/step\n",
            "Epoch 85/100\n",
            "14/14 - 0s - loss: 0.4784 - accuracy: 0.9366 - 144ms/epoch - 10ms/step\n",
            "Epoch 86/100\n",
            "14/14 - 0s - loss: 0.4630 - accuracy: 0.9319 - 216ms/epoch - 15ms/step\n",
            "Epoch 87/100\n",
            "14/14 - 0s - loss: 0.4321 - accuracy: 0.9460 - 139ms/epoch - 10ms/step\n",
            "Epoch 88/100\n",
            "14/14 - 0s - loss: 0.4166 - accuracy: 0.9531 - 89ms/epoch - 6ms/step\n",
            "Epoch 89/100\n",
            "14/14 - 0s - loss: 0.4024 - accuracy: 0.9507 - 86ms/epoch - 6ms/step\n",
            "Epoch 90/100\n",
            "14/14 - 0s - loss: 0.3930 - accuracy: 0.9601 - 148ms/epoch - 11ms/step\n",
            "Epoch 91/100\n",
            "14/14 - 0s - loss: 0.3792 - accuracy: 0.9577 - 108ms/epoch - 8ms/step\n",
            "Epoch 92/100\n",
            "14/14 - 0s - loss: 0.3687 - accuracy: 0.9648 - 100ms/epoch - 7ms/step\n",
            "Epoch 93/100\n",
            "14/14 - 0s - loss: 0.3596 - accuracy: 0.9601 - 131ms/epoch - 9ms/step\n",
            "Epoch 94/100\n",
            "14/14 - 0s - loss: 0.3494 - accuracy: 0.9648 - 191ms/epoch - 14ms/step\n",
            "Epoch 95/100\n",
            "14/14 - 0s - loss: 0.3390 - accuracy: 0.9648 - 105ms/epoch - 8ms/step\n",
            "Epoch 96/100\n",
            "14/14 - 0s - loss: 0.3293 - accuracy: 0.9671 - 94ms/epoch - 7ms/step\n",
            "Epoch 97/100\n",
            "14/14 - 0s - loss: 0.3170 - accuracy: 0.9718 - 126ms/epoch - 9ms/step\n",
            "Epoch 98/100\n",
            "14/14 - 0s - loss: 0.3132 - accuracy: 0.9718 - 87ms/epoch - 6ms/step\n",
            "Epoch 99/100\n",
            "14/14 - 0s - loss: 0.3043 - accuracy: 0.9695 - 92ms/epoch - 7ms/step\n",
            "Epoch 100/100\n",
            "14/14 - 0s - loss: 0.3010 - accuracy: 0.9695 - 161ms/epoch - 12ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe7275331d0>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(model, char_to_index, seq_length, seed_text, n):\n",
        "\n",
        "  init_text = seed_text\n",
        "  sentence = ''\n",
        "\n",
        "  for _ in range(n):\n",
        "    encoded = [char_to_index[char] for char in seed_text]\n",
        "    encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre')\n",
        "    encoded = to_categorical(encoded, num_classes=len(char_to_index))\n",
        "\n",
        "    result = model.predict(encoded, verbose=0)\n",
        "    result = np.argmax(result, axis=1)\n",
        "\n",
        "    for char, index in char_to_index.items():\n",
        "      if index == result:\n",
        "        break\n",
        "      \n",
        "    seed_text = seed_text + char\n",
        "    sentence = sentence + char\n",
        "  sentence = init_text + sentence\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "d3J9VHQC-wdG"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, char_to_index, 10, 'I get on w', 80))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzXQm7zkAsK7",
        "outputId": "12d5e688-788b-48f1-c0d0-0be444216c04"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I get on with life as a programmer, I like to cse wiint toest tldivw ae ,rrrr. tht  uueer.\n"
          ]
        }
      ]
    }
  ]
}